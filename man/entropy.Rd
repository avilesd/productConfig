% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/WeightFunctions.R
\name{entropy}
\alias{entropy}
\title{Calculates decision weights using the entrophy method}
\usage{
entropy(normalizedMatrix)
}
\arguments{
\item{normalizedMatrix}{a numeric matrix. If indeed normalized it should only
contain values between \code{0} and \code{1}.}
}
\value{
a decision weight (numeric vector with a sum of 1)
}
\description{
This function is used as the second step in \code{\link{weight.entropy}} for
calculating a decision weight for each \code{\link{attr}} in the decision
matrix. The methodology of the entropy method [2] for determining the weights
out of a decision matrix is given by references [1] and [3]. See Details.
}
\details{
The sum of the output of this functions should always equal 1.

Contrasting with \code{\link{differenceToIdeal}} small differences
  between value attributes are rewarded a lower value and thus a relative
  lower weight.

  Note: the normalizing function used here \code{\link{normalize.sum}} has
  one limitation, if within a same attribute there are negative and positive
  values, the function will likely produce a \code{NaN}.
}
\examples{
#Runnable
entropy(matrix(c(1.0, 0.85, 0.42, 0, 0.5, 0, 1, 0.7), 4, 2))
weights <- entropy(matrix(c(1.0, 0.85, 0.42, 0, 0.5, 0, 1, 0.7), 2, 4))
sum(entropy) should return 1

}
\references{
[1]Hwang, C. L., & Yoon, K. (2012). Multiple attribute decision
  making: methods and applications a state-of-the-art survey (Vol. 186).
  Springer Science & Business Media.

  [2]Shannon, C. E. (2001). A mathematical theory of communication. ACM
  SIGMOBILE Mobile Computing and Communications Review, 5(1), 35.

  [3]Lotfi, F. H., and Fallahnejad, R. (2010). Imprecise Shannons entropy and
  multi attribute decision making. Entropy, 12(1), 53-62.
}

